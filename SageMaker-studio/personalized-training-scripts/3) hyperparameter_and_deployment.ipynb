{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning in SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
      "     |████████████████████████████████| 23.3 MB 21.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.4.0)\n",
      "Collecting torch==1.10.0\n",
      "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 85.8 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-1.10.0 torchvision-0.11.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-cifar\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "local_dir = 'data'\n",
    "CIFAR10.mirrors = [\"https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/CIFAR10/\"]\n",
    "CIFAR10(\n",
    "    local_dir,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-east-1-678049007427/sagemaker/DEMO-pytorch-cifar\n"
     ]
    }
   ],
   "source": [
    "# TODO: Upload the data to an S3 bucket. You can use the sagemaker_session object, boto3 or the AWS CLI\n",
    "inputs = sagemaker_session.upload_data(path=\"data\", bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    source_dir=\"./scripts\",\n",
    "    entry_point=\"cifar.py\",\n",
    "    role=role,\n",
    "    py_version='py36',\n",
    "    framework_version=\"1.8\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.001, 0.1),\n",
    "    \"batch-size\": CategoricalParameter([32, 64, 128, 256, 512]),\n",
    "    \"epochs\": IntegerParameter(2, 4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"average test loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"average test loss\", \"Regex\": \"Test set: Average loss: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({\"training\": inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-12-01 21:41:51 Starting - Preparing the instances for training\n",
      "2021-12-01 21:41:51 Downloading - Downloading input data\n",
      "2021-12-01 21:41:51 Training - Training image download completed. Training in progress.\n",
      "2021-12-01 21:41:51 Uploading - Uploading generated training model\n",
      "2021-12-01 21:41:51 Completed - Training job completed\n",
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor = tuner.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-17-b07d256e50a7>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-b07d256e50a7>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    \"\"\"\"\u001b[0m\n\u001b[0m        \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "estimator = sagemaker.estimator.Estimator.attach(\"pytorch-training-211201-0222-004-56013d5a\")  \n",
    "\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.t2.medium'\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "file = 'data/cifar-10-batches-py/data_batch_1'\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "data=unpickle(file)\n",
    "data=np.reshape(data[b'data'][0], (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.expand_dims(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 59.  43.  50. ... 158. 152. 148.]\n",
      "   [ 16.   0.  18. ... 123. 119. 122.]\n",
      "   [ 25.  16.  49. ... 118. 120. 109.]\n",
      "   ...\n",
      "   [208. 201. 198. ... 160.  56.  53.]\n",
      "   [180. 173. 186. ... 184.  97.  83.]\n",
      "   [177. 168. 179. ... 216. 151. 123.]]\n",
      "\n",
      "  [[ 62.  46.  48. ... 132. 125. 124.]\n",
      "   [ 20.   0.   8. ...  88.  83.  87.]\n",
      "   [ 24.   7.  27. ...  84.  84.  73.]\n",
      "   ...\n",
      "   [170. 153. 161. ... 133.  31.  34.]\n",
      "   [139. 123. 144. ... 148.  62.  53.]\n",
      "   [144. 129. 142. ... 184. 118.  92.]]\n",
      "\n",
      "  [[ 63.  45.  43. ... 108. 102. 103.]\n",
      "   [ 20.   0.   0. ...  55.  50.  57.]\n",
      "   [ 21.   0.   8. ...  50.  50.  42.]\n",
      "   ...\n",
      "   [ 96.  34.  26. ...  70.   7.  20.]\n",
      "   [ 96.  42.  30. ...  94.  34.  34.]\n",
      "   [116.  94.  87. ... 140.  84.  72.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(data.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"expected scalar type Double but found Float\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_inference/transformer.py\", line 126, in transform\n    result = self._transform_fn(self._model, input_data, content_type, accept)\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_inference/transformer.py\", line 216, in _default_transform_fn\n    prediction = self._predict_fn(data, model)\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_serving_container/default_pytorch_inference_handler.py\", line 125, in default_predict_fn\n    output = model(input_data)\n  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/ml/model/code/cifar.py\", line 33, in forward\n    x = self.pool(F.relu(self.conv1(x)))\n  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 399, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 396, in _conv_forward\n    self.padding, self.dilation, self.groups)\nRuntimeError: expected scalar type Double but found Float\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-training-211201-2136-001-70b9da77 in account 678049007427 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-b9f700ea6938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# .tobytes()?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"expected scalar type Double but found Float\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_inference/transformer.py\", line 126, in transform\n    result = self._transform_fn(self._model, input_data, content_type, accept)\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_inference/transformer.py\", line 216, in _default_transform_fn\n    prediction = self._predict_fn(data, model)\n  File \"/opt/conda/lib/python3.6/site-packages/sagemaker_pytorch_serving_container/default_pytorch_inference_handler.py\", line 125, in default_predict_fn\n    output = model(input_data)\n  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/ml/model/code/cifar.py\", line 33, in forward\n    x = self.pool(F.relu(self.conv1(x)))\n  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 399, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 396, in _conv_forward\n    self.padding, self.dilation, self.groups)\nRuntimeError: expected scalar type Double but found Float\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-training-211201-2136-001-70b9da77 in account 678049007427 for more information."
     ]
    }
   ],
   "source": [
    "#from sagemaker.serializers import IdentitySerializer\n",
    "#predictor.serializer = IdentitySerializer(\"image/png\")\n",
    "# .tobytes()?\n",
    "\n",
    "response = predictor.predict(data.astype(float))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "After you have finished with this exercise, remember to delete the prediction endpoint to release the instance associated with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 59,  43,  50,  ..., 158, 152, 148],\n",
      "          [ 16,   0,  18,  ..., 123, 119, 122],\n",
      "          [ 25,  16,  49,  ..., 118, 120, 109],\n",
      "          ...,\n",
      "          [208, 201, 198,  ..., 160,  56,  53],\n",
      "          [180, 173, 186,  ..., 184,  97,  83],\n",
      "          [177, 168, 179,  ..., 216, 151, 123]],\n",
      "\n",
      "         [[ 62,  46,  48,  ..., 132, 125, 124],\n",
      "          [ 20,   0,   8,  ...,  88,  83,  87],\n",
      "          [ 24,   7,  27,  ...,  84,  84,  73],\n",
      "          ...,\n",
      "          [170, 153, 161,  ..., 133,  31,  34],\n",
      "          [139, 123, 144,  ..., 148,  62,  53],\n",
      "          [144, 129, 142,  ..., 184, 118,  92]],\n",
      "\n",
      "         [[ 63,  45,  43,  ..., 108, 102, 103],\n",
      "          [ 20,   0,   0,  ...,  55,  50,  57],\n",
      "          [ 21,   0,   8,  ...,  50,  50,  42],\n",
      "          ...,\n",
      "          [ 96,  34,  26,  ...,  70,   7,  20],\n",
      "          [ 96,  42,  30,  ...,  94,  34,  34],\n",
      "          [116,  94,  87,  ..., 140,  84,  72]]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "print(torch.tensor(data).to(torch.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
